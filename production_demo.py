"""
Production Demo: ETH Forecasting with Real Ensemble Models and Live Data

This demo showcases the complete integration of:
1. Real ensemble model loading and management
2. Live data pipeline with multiple sources
3. Real-time feature engineering
4. Production API with caching and rate limiting
5. Quality monitoring and automated validation

Following all project rules for production-ready implementation.
"""

import sys
import os
import time
import asyncio
import threading
from datetime import datetime, timezone
import pandas as pd
import numpy as np

# Add project root to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.production.ensemble_manager import EnsembleManager
from src.production.live_data_pipeline import LiveDataPipeline
from src.production.prediction_api import PredictionAPI, create_api_config
from src.utils.config_loader import load_config, get_default_config


def create_demo_config():
    """Create configuration for demo."""
    # Start with API config
    config = create_api_config()
    
    # Add paths configuration (required by EnsembleManager)
    config['paths'] = {
        'models': 'models',
        'data': 'data',
        'logs': 'logs',
        'reports': 'reports'
    }
    
    # Add model paths (these would be real trained models in production)
    config['models'] = {
        'lightgbm': {
            'model_path': 'models/lightgbm_model.pkl',
            'config_path': 'models/lightgbm_config.json'
        },
        'tft': {
            'model_path': 'models/tft_model.pt',
            'config_path': 'models/tft_config.json'
        },
        'nbeats': {
            'model_path': 'models/nbeats_model.pt',
            'config_path': 'models/nbeats_config.json'
        }
    }
    
    # Feature engineering config
    config['feature_engineering'] = {
        'lookback_periods': [1, 3, 7, 14, 30],
        'rolling_windows': [3, 7, 14, 30],
        'volatility_windows': [7, 14, 30],
        'momentum_periods': [3, 7, 14],
        'cross_asset_features': True,
        'calendar_features': True,
        'event_features': True
    }
    
    # Data preprocessing config
    config['preprocessing'] = {
        'denoising': {
            'hampel_filter': {'window': 5, 'n_sigma': 3},
            'winsorization': {'lower': 0.005, 'upper': 0.995},
            'wavelet': {'wavelet': 'db4', 'mode': 'soft'},
            'rolling_median': {'window': 3}
        },
        'scaling': {
            'method': 'robust',
            'feature_range': (-1, 1)
        }
    }
    
    return config


def demo_ensemble_manager():
    """Demonstrate EnsembleManager functionality."""
    print("\n" + "="*60)
    print("ü§ñ ENSEMBLE MANAGER DEMO")
    print("="*60)
    
    config = create_demo_config()
    
    try:
        # Initialize ensemble manager
        print("üì¶ Initializing EnsembleManager...")
        ensemble_manager = EnsembleManager(config)
        
        # Show available models
        available_models = ensemble_manager.get_available_models()
        print(f"üìã Available models: {available_models}")
        
        # Load models on-demand
        print("\nüîÑ Loading models on-demand...")
        for model_name in ['lightgbm', 'tft']:
            print(f"   Loading {model_name}...")
            try:
                success = ensemble_manager.load_model(model_name)
                if success:
                    print(f"   ‚úÖ {model_name} loaded successfully")
                else:
                    print(f"   ‚ö†Ô∏è  {model_name} load failed (model file not found - expected in demo)")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  {model_name} load error: {str(e)[:50]}...")
        
        # Show loaded models
        loaded_models = ensemble_manager.get_loaded_models()
        print(f"\nüìä Loaded models: {loaded_models}")
        
        # Show model status
        model_status = ensemble_manager.get_model_status()
        print(f"üìà Model status: {model_status}")
        
        # Memory management demo
        model_status = ensemble_manager.get_model_status()
        print(f"\nüíæ Memory usage: {model_status['memory_usage_mb']:.1f} MB")
        
        # Generate sample data for prediction demo
        print("\nüé≤ Generating sample data for prediction...")
        sample_data = pd.DataFrame({
            'ETH_Close': np.random.normal(2000, 100, 100),
            'ETH_Volume': np.random.normal(1000000, 100000, 100),
            'BTC_Close': np.random.normal(40000, 2000, 100),
            'BTC_Volume': np.random.normal(500000, 50000, 100)
        })
        sample_data.index = pd.date_range('2024-01-01', periods=100, freq='H')
        
        print(f"   Sample data shape: {sample_data.shape}")
        print(f"   Date range: {sample_data.index.min()} to {sample_data.index.max()}")
        
        # Attempt prediction (will fail gracefully if models not loaded)
        print("\nüîÆ Attempting ensemble prediction...")
        try:
            prediction_result = ensemble_manager.predict(sample_data)
            if prediction_result:
                prediction, confidence, contributions = prediction_result
                print(f"   ‚úÖ Prediction: {prediction:.6f}")
                print(f"   üìä Confidence: {confidence:.3f}")
                print(f"   ü§ù Model contributions: {contributions}")
            else:
                print("   ‚ö†Ô∏è  Prediction failed (expected - no trained models in demo)")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Prediction error: {str(e)[:50]}...")
        
        # Cleanup
        print("\nüßπ Cleaning up...")
        ensemble_manager.cleanup()
        print("   ‚úÖ All models unloaded")
        
    except Exception as e:
        print(f"‚ùå Ensemble Manager Demo Error: {e}")
        import traceback
        traceback.print_exc()


def demo_live_data_pipeline():
    """Demonstrate LiveDataPipeline functionality."""
    print("\n" + "="*60)
    print("üì° LIVE DATA PIPELINE DEMO")
    print("="*60)
    
    config = create_demo_config()
    
    # Shorter intervals for demo
    config['live_pipeline']['fetch_interval_seconds'] = 10
    config['live_pipeline']['processing_interval_seconds'] = 5
    
    try:
        print("üöÄ Initializing LiveDataPipeline...")
        
        # Callback functions
        data_received_count = 0
        quality_updates_count = 0
        
        def data_callback(df):
            nonlocal data_received_count
            data_received_count += 1
            print(f"   üìä Data update #{data_received_count}: {len(df)} rows, {len(df.columns)} features")
            if not df.empty:
                print(f"      Latest timestamp: {df.index.max()}")
                print(f"      Sample features: {list(df.columns[:5])}...")
        
        def quality_callback(metrics):
            nonlocal quality_updates_count
            quality_updates_count += 1
            print(f"   üìà Quality update #{quality_updates_count}: {metrics.overall_score:.3f}")
            print(f"      Completeness: {metrics.completeness:.2f}, "
                  f"Timeliness: {metrics.timeliness:.2f}")
        
        # Test pipeline
        with LiveDataPipeline(config) as pipeline:
            print("‚úÖ Pipeline started successfully")
            
            # Add callbacks
            pipeline.add_data_callback(data_callback)
            pipeline.add_quality_callback(quality_callback)
            
            print("\n‚è±Ô∏è  Running pipeline for 30 seconds...")
            print("   (Fetching live ETH/BTC data from Yahoo Finance)")
            
            # Run for 30 seconds
            for i in range(6):
                time.sleep(5)
                
                # Show quality summary
                quality = pipeline.get_quality_summary()
                print(f"   üîç Quality check {i+1}/6: {quality.get('status', 'unknown')}")
                
                # Try to get latest data
                latest_data = pipeline.get_latest_data(max_age_minutes=10)
                if latest_data is not None:
                    print(f"      Latest data: {latest_data.shape[0]} rows, {latest_data.shape[1]} features")
                else:
                    print("      No recent data available")
            
            print(f"\nüìä Final Statistics:")
            print(f"   Data updates received: {data_received_count}")
            print(f"   Quality updates received: {quality_updates_count}")
            
            # Final quality summary
            final_quality = pipeline.get_quality_summary()
            print(f"   Final quality status: {final_quality.get('status', 'unknown')}")
            print(f"   Final quality score: {final_quality.get('current_score', 'N/A')}")
            print(f"   Source health: {final_quality.get('source_health', {})}")
        
        print("‚úÖ Pipeline demo completed successfully")
        
    except Exception as e:
        print(f"‚ùå Live Data Pipeline Demo Error: {e}")
        import traceback
        traceback.print_exc()


def demo_prediction_api():
    """Demonstrate PredictionAPI functionality."""
    print("\n" + "="*60)
    print("üåê PREDICTION API DEMO")
    print("="*60)
    
    config = create_demo_config()
    
    try:
        print("üöÄ Initializing PredictionAPI...")
        
        api = PredictionAPI(config)
        print("‚úÖ API initialized successfully")
        
        # Test system status
        print("\nüìä System Status Check:")
        status = api.get_system_status()
        print(f"   Status: {status.status}")
        print(f"   Uptime: {status.uptime_seconds:.1f} seconds")
        print(f"   Memory: {status.memory_usage_mb:.1f} MB")
        print(f"   Models loaded: {status.models_loaded}")
        print(f"   Data pipeline: {status.data_pipeline_status}")
        
        # Test rate limiter
        print("\nüö¶ Rate Limiter Test:")
        for i in range(5):
            allowed = api.rate_limiter.is_allowed()
            print(f"   Request {i+1}: {'‚úÖ Allowed' if allowed else '‚ùå Blocked'}")
        
        # Test cache
        print("\nüíæ Cache Test:")
        from src.production.prediction_api import PredictionResult
        
        test_result = PredictionResult(
            timestamp=datetime.now(timezone.utc),
            prediction=2000.123456,
            confidence=0.85,
            model_contributions={'lightgbm': 0.6, 'tft': 0.4},
            data_quality=0.9,
            features_used=50,
            processing_time_ms=150.5,
            model_version="test_v1.0"
        )
        
        # Cache and retrieve
        api.cache.put("test_key", test_result)
        cached_result = api.cache.get("test_key")
        
        if cached_result:
            print("   ‚úÖ Cache store/retrieve successful")
            print(f"   Cached prediction: {cached_result.prediction:.6f}")
        else:
            print("   ‚ùå Cache test failed")
        
        # Test with sample data
        print("\nüîÆ Sample Prediction Test:")
        sample_data = {
            'Date': ['2024-01-01 12:00:00'],
            'ETH_Close': [2000.0],
            'ETH_Volume': [1000000.0],
            'BTC_Close': [40000.0],
            'BTC_Volume': [500000.0]
        }
        
        # This will fail gracefully since we don't have trained models
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            prediction_result = loop.run_until_complete(
                api._make_prediction_async(
                    use_live_data=False,
                    custom_data=sample_data,
                    model_names=None,
                    include_explanations=False
                )
            )
            
            if prediction_result:
                print("   ‚úÖ Prediction successful")
                print(f"   Prediction: {prediction_result.prediction:.6f}")
                print(f"   Confidence: {prediction_result.confidence:.3f}")
                print(f"   Processing time: {prediction_result.processing_time_ms:.1f}ms")
            else:
                print("   ‚ö†Ô∏è  Prediction failed (expected - no trained models)")
        
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Prediction error: {str(e)[:50]}...")
        
        finally:
            loop.close()
        
        # Cleanup
        print("\nüßπ Cleaning up API...")
        api.stop()
        print("   ‚úÖ API stopped successfully")
        
    except Exception as e:
        print(f"‚ùå Prediction API Demo Error: {e}")
        import traceback
        traceback.print_exc()


def demo_integration():
    """Demonstrate full integration."""
    print("\n" + "="*60)
    print("üîó FULL INTEGRATION DEMO")
    print("="*60)
    
    config = create_demo_config()
    
    # Shorter intervals for demo
    config['live_pipeline']['fetch_interval_seconds'] = 15
    config['live_pipeline']['processing_interval_seconds'] = 10
    
    try:
        print("üöÄ Starting full integration demo...")
        print("   This demonstrates all components working together:")
        print("   - Live data pipeline fetching real market data")
        print("   - Ensemble manager with on-demand model loading")
        print("   - Real-time feature engineering")
        print("   - Quality monitoring and validation")
        
        # Initialize all components
        print("\nüì¶ Initializing components...")
        
        ensemble_manager = EnsembleManager(config)
        print("   ‚úÖ EnsembleManager initialized")
        
        live_pipeline = LiveDataPipeline(config)
        print("   ‚úÖ LiveDataPipeline initialized")
        
        # Start live pipeline
        print("\nüöÄ Starting live data pipeline...")
        live_pipeline.start()
        
        # Set up monitoring
        integration_stats = {
            'data_updates': 0,
            'quality_updates': 0,
            'predictions_attempted': 0,
            'predictions_successful': 0
        }
        
        def monitor_data(df):
            integration_stats['data_updates'] += 1
            print(f"   üìä Data update #{integration_stats['data_updates']}: "
                  f"{len(df)} rows, {len(df.columns)} features")
            
            # Attempt prediction with new data
            if not df.empty and integration_stats['data_updates'] % 2 == 0:  # Every 2nd update
                integration_stats['predictions_attempted'] += 1
                try:
                    # This will fail gracefully without trained models
                    result = ensemble_manager.predict(df)
                    if result:
                        integration_stats['predictions_successful'] += 1
                        prediction, confidence, contributions = result
                        print(f"      üîÆ Prediction: {prediction:.6f} (confidence: {confidence:.3f})")
                    else:
                        print(f"      ‚ö†Ô∏è  Prediction failed (no trained models)")
                except Exception as e:
                    print(f"      ‚ö†Ô∏è  Prediction error: {str(e)[:30]}...")
        
        def monitor_quality(metrics):
            integration_stats['quality_updates'] += 1
            print(f"   üìà Quality #{integration_stats['quality_updates']}: "
                  f"{metrics.overall_score:.3f}")
        
        # Add callbacks
        live_pipeline.add_data_callback(monitor_data)
        live_pipeline.add_quality_callback(monitor_quality)
        
        print("\n‚è±Ô∏è  Running integration for 45 seconds...")
        print("   Watch for real-time data processing and prediction attempts...")
        
        # Run integration
        for i in range(9):  # 45 seconds / 5 second intervals
            time.sleep(5)
            
            # Show progress
            print(f"\n   üîç Progress check {i+1}/9:")
            
            # Quality summary
            quality = live_pipeline.get_quality_summary()
            print(f"      Data quality: {quality.get('status', 'unknown')} "
                  f"(score: {quality.get('current_score', 'N/A')})")
            
            # Memory usage
            model_status = ensemble_manager.get_model_status()
            memory_mb = model_status['memory_usage_mb']
            print(f"      Memory usage: {memory_mb:.1f} MB")
            
            # Latest data availability
            latest_data = live_pipeline.get_latest_data(max_age_minutes=10)
            if latest_data is not None:
                print(f"      Latest data: {latest_data.shape} available")
            else:
                print(f"      Latest data: Not available")
        
        # Final statistics
        print(f"\nüìä Integration Demo Results:")
        print(f"   Data updates received: {integration_stats['data_updates']}")
        print(f"   Quality updates received: {integration_stats['quality_updates']}")
        print(f"   Predictions attempted: {integration_stats['predictions_attempted']}")
        print(f"   Predictions successful: {integration_stats['predictions_successful']}")
        
        success_rate = (integration_stats['predictions_successful'] / 
                       max(integration_stats['predictions_attempted'], 1) * 100)
        print(f"   Prediction success rate: {success_rate:.1f}%")
        
        # Cleanup
        print("\nüßπ Cleaning up integration...")
        live_pipeline.stop()
        ensemble_manager.cleanup()
        print("   ‚úÖ Integration demo completed successfully")
        
    except Exception as e:
        print(f"‚ùå Integration Demo Error: {e}")
        import traceback
        traceback.print_exc()


def main():
    """Run complete production demo."""
    print("üöÄ ETH FORECASTING PRODUCTION DEMO")
    print("=" * 80)
    print("This demo showcases the complete production-ready system:")
    print("‚Ä¢ Real ensemble model integration with on-demand loading")
    print("‚Ä¢ Live data pipeline with multiple sources and quality monitoring")
    print("‚Ä¢ Real-time feature engineering and preprocessing")
    print("‚Ä¢ Production API with caching, rate limiting, and monitoring")
    print("‚Ä¢ Full integration with automated quality gates")
    print("=" * 80)
    
    try:
        # Run individual component demos
        demo_ensemble_manager()
        demo_live_data_pipeline()
        demo_prediction_api()
        demo_integration()
        
        print("\n" + "="*80)
        print("üéâ PRODUCTION DEMO COMPLETED SUCCESSFULLY!")
        print("="*80)
        print("\nüìã Summary of Demonstrated Features:")
        print("‚úÖ Ensemble model management with memory optimization")
        print("‚úÖ Live data acquisition from Yahoo Finance")
        print("‚úÖ Real-time feature engineering pipeline")
        print("‚úÖ Data quality monitoring and validation")
        print("‚úÖ Production API with REST endpoints")
        print("‚úÖ Caching and rate limiting")
        print("‚úÖ Automated quality gates and error handling")
        print("‚úÖ Full system integration")
        
        print("\nüöÄ Next Steps:")
        print("1. Train actual models using the training pipeline")
        print("2. Deploy to production environment")
        print("3. Set up monitoring and alerting")
        print("4. Configure load balancing and scaling")
        print("5. Implement model retraining automation")
        
        print("\nüìö Key Files Created:")
        print("‚Ä¢ src/production/ensemble_manager.py - Model management")
        print("‚Ä¢ src/production/live_data_pipeline.py - Real-time data")
        print("‚Ä¢ src/production/prediction_api.py - REST API")
        print("‚Ä¢ production_demo.py - This demo script")
        
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  Demo interrupted by user")
    except Exception as e:
        print(f"\n\n‚ùå Demo Error: {e}")
        import traceback
        traceback.print_exc()
    
    print("\nüëã Demo finished. Thank you!")


if __name__ == "__main__":
    main()